C++ Implementation of Sørensen–Dice Coefficient Based String Similarity
=======================================================================

This library may be used to compare strings by a similarity measure, defined as
Sørensen–Dice coefficient calculated on multi-sets of the strings' "bigrams"
(all couples of adjacent characters).

Bigram (multi-)set is relatively easy to generate (_O(n)_ time complexity lower bound
in terms of the string length).

Also, compared to just using a (multi-)set of characters, bigrams do retain certain
level of word structure.
E.g. backwards spelled words are not deemed similar (unlike when single character
set is used).

Just note that single-character words are all perfectly similar in this metric,
as their bigram sets are empty---and therefore the same.
It may be a good idea to augment words like that with an additional character (like
a whitespace) to mitigate that problem.

Seek more info in References section below.


List of features
----------------

* Bigram multi-set objects implemented as sorted lists of character tuples with count
  (_O(n log n)_ creation time complexity in terms of the string length)
* Union operation has _O(m+n)_ time complexity (sum of multi-sets' cardinalities at most)
* Intersection doesn't produce objects; only its size is calculated in _O(m+n)_ time
* Template implementation, allowing for both ASCII/ANSI characters and UNICODE characters
* Implementations using `std::multiset` and `std::unordered_multiset` also available
* Performance tests show that, long story short, the "custom" implementation is the best
  (notably faster unions, intersection size computation in similar or better time)
* Python v3 binding is provided (as `pysdc` module, packaged)
* Python `multiset` based implementation also compared---and is expectedly much slower


Build and installation
----------------------

You shall need C\++ compiler with support for at least C++14.
Recent enough gcc (v8.3 or newer) is OK (older versions might do as well, though).
You shall also need `cmake` and `make`.

Python v3.7 or newer is supported.
For the Python package build, you shall need `pip` and Python `distutils`
and the `wheel` package.
If you wish to run Python UTs (which is highly recommended), you shall also need `pytest`.

E.g. on Debian-based (or similar, `apt` using) systems, the following should get you
the required prerequisites unless you wish to use `pyenv`.

[source]
----
# apt-get install g++ cmake make git
# apt-get install python3-pip python3-distutils  # unless you use pyenv
$ pip install wheel pytest                       # ditto, better do that in pyenv sandbox
----

On Mac OS X, you'll need Xcode tools and Homebrew.
Then, install the required prerequisites by
[source]
----
$ brew install coreutils cmake make
----

If you do wish to use `pyenv` to create and manage project sandbox (which is advisable),
see short intro to that in the subsection below.

Anyhow, with all the prerequisites installed, clone the project:
[source]
----
$ git clone https://github.com/vencik/libsdcxx.git
----

Build the project, run UTs and build Python package:
[source]
----
$ cd libsdcxx
$ ./build.sh
----

Note that the `build.sh` script has options; run `$ ./build.sh -h` to see them.

Most importantly, run with `-s` or `--enable-pt` options to perform performance tests.
Performance tests compare computation times of object construction, union operations
and intersection size computations of the implementations.
If you install `multiset` Python package (using `pip`), the perf. tests shall also
produce results for pure-Python implementation using `multiset.Multiset` (not necessary).

NOTE: The perf. tests are written on the Python level, so the measured times also contain
some Python code runtime (and not trivial).
I'd expect results in native code to be notably better; but the test code is identical,
so the measurements should be meaningful for comparison.

If you wish, use `pip` to install the Python package:
[source]
----
# pip install pysdc-*.whl
----

Note that it's recommended to use `pyenv`, especially for development purposes.


Managing project sandbox with `pyenv`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

First install `pyenv`.
You may use either your OS package repo (Homebrew on Mac OS X) or web `pyenv` installer.
Setup `pyenv` (set environment variables) as instructed.

Then, create `pysdc` project sandbox, thus:
[source]
----
$ pyenv install 3.9.6  # your choice of the Python interpreter version, >= 3.7
$ pyenv virtualenv 3.9.6 pysdc
----

Now, you can always (de)activate the virtual environment (switch to the sandbox) by
[source]
----
# pyenv activate pysdc
# pyenv deactivate
----

In the sandbox, install Python packages using `pip` as usual.

[source]
----
$ pip install wheel pytest
----


Usage
-----

C++
~~~

[source, C++]
----
#import <libsdcxx/bigrams.hxx>

using bigrams = libsdcxx::bigrams;                            // wbigrams for UNICODE

const auto bgrms_empty = bigrams();                           // empty bigrams set

const auto bgrms1 = bigrams("Hello world!");                  // construct from string
size_t cnt = bgrms1.size();                                   // number of bigrams

std::cout << bgrms1;                                          // serialisation

for (const auto & bigram_cnt: bgrms1) {                       // tuple of (bigram, count)
    const auto & bigram = std::get<0>(bigram_cnt);

    std::cout << "Bigram : " << std::get<0>(bigram) << std::get<1>(bigram) << std::endl;
    std::cout << "Count  : " << std::get<1>(bigram_cnt) << std::endl;
}

// (Const.) iterators are supported via cbegin, cend and begin, end method calls

const auto bgrms2 = bigrams("Hell or woes.");

size_t isect_size = bigrams::intersect_size(bgrms1, bgrms2);  // intersection cardinality
double sdc = bigrams.sorensen_dice_coef(bgrms1, bgrms2);      // similarity, in [0,1]

auto uni0n = bgrms1 + bgrms2;                                 // 2 bigrams union
auto uni0n = bigrams::unite(bgrms1, bgrms2 /* , ... */);      // variadic union

uni0n += bigrams("more stuff");                               // objects are mutable
----


Pyton v3
~~~~~~~~

[source, Python]
----
from pysdc import Bigrams   # Python Bigrams are implemented by wbigrams, support UNICODE

bgrms_empty = Bigrams()                 # empty bigrams set

bgrms1 = Bigrams("Hello world!")        # construct from string
cnt = len(bgrms1)                       # number of bigrams

print(str(bgrms1), f"{bgrms1}")         # string serialisation

for bigram, cnt in bgrms1:              # Bigrams are tuple[str, int] generators
    assert len(bigram) == 2

bgrms2 = Bigrams("Hell or woes.")

isect_size = Bigrams.intersect_size(bgrms1, bgrms2)     # intersection cardinality
sdc = Bigrams.sorensen_dice_coef(bgrms1, bgrms2)        # simiarity, in [0,1]

union = bgrms1 + bgrms2                                 # 2 bigrams union

union += Bigrams("more stuff")                          # objects are mutable
----


License
-------

The software is available open-source under the terms of 3-clause BSD license.


References
----------

https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient


Author
------

Václav Krpec  <vencik@razdva.cz>
